apiVersion: v1
data:
  k8s-worker-script.py: "#!/usr/bin/env python3\n\"\"\"\nKubernetes Honest Worker\
    \ Script\nExecutes tasks with local LLM support and cryptographic proof\n\"\"\"\
    \n\nimport json\nimport os\nimport time\nimport hashlib\nimport requests\nfrom\
    \ pathlib import Path\n\nclass HonestK8sWorker:\n    def __init__(self, worker_id,\
    \ tasks):\n        self.worker_id = worker_id\n        self.tasks = tasks\n  \
    \      self.llm_endpoint = os.getenv('LLM_ENDPOINT')\n        self.results = {\n\
    \            'worker_id': worker_id,\n            'start_time': time.time(),\n\
    \            'tasks_completed': 0,\n            'tasks_failed': 0,\n         \
    \   'cryptographic_proofs': []\n        }\n\n    def query_local_llm(self, prompt):\n\
    \        \"\"\"Query local Ollama LLM\"\"\"\n        try:\n            response\
    \ = requests.post(\n                f'http://{self.llm_endpoint}/api/generate',\n\
    \                json={\n                    'model': 'codellama:7b',\n      \
    \              'prompt': prompt,\n                    'stream': False\n      \
    \          },\n                timeout=60\n            )\n            return response.json().get('response',\
    \ '')\n        except Exception as e:\n            print(f\"\u26A0\uFE0F  LLM\
    \ query failed: {e}\")\n            return None\n\n    def execute_task(self,\
    \ task):\n        \"\"\"Execute a single task with cryptographic proof\"\"\"\n\
    \        print(f\"\\n\U0001F527 Executing: {task.get('key_metric', 'Unknown')}\"\
    )\n        print(f\"   Severity: {task.get('severity', 'Unknown')}\")\n      \
    \  print(f\"   Sheet: {task.get('sheet', 'Unknown')}\")\n\n        # Generate\
    \ analysis using local LLM\n        analysis_prompt = f\"\"\"\nTask: {task.get('finding',\
    \ '')}\nProposed Solution: {task.get('solution', '')}\n\nGenerate a concise implementation\
    \ plan with:\n1. Exact file modifications needed\n2. Code changes with before/after\n\
    3. Testing approach\n4. Risk assessment\n\nBe specific and actionable.\n\"\"\"\
    \n\n        analysis = self.query_local_llm(analysis_prompt)\n\n        if analysis:\n\
    \            # Simulate cryptographic proof (in real impl, would modify files)\n\
    \            proof = {\n                'task_id': task.get('key_metric'),\n \
    \               'task_source': task.get('source'),\n                'analysis_hash':\
    \ hashlib.md5(analysis.encode()).hexdigest(),\n                'llm_used': 'codellama:7b\
    \ (local)',\n                'api_cost_saved': 0.015,  # vs Anthropic\n      \
    \          'timestamp': time.time()\n            }\n\n            self.results['cryptographic_proofs'].append(proof)\n\
    \            self.results['tasks_completed'] += 1\n\n            print(f\"\u2705\
    \ Task completed with local LLM\")\n            print(f\"   API Cost Saved: $0.015\"\
    )\n            print(f\"   Analysis Hash: {proof['analysis_hash'][:16]}...\")\n\
    \n            return True\n        else:\n            self.results['tasks_failed']\
    \ += 1\n            print(f\"\u274C Task failed - LLM unavailable\")\n       \
    \     return False\n\n    def run(self):\n        \"\"\"Execute all tasks\"\"\"\
    \n        print(f\"\\n{'='*80}\")\n        print(f\"K8S WORKER: {self.worker_id}\"\
    )\n        print(f\"Tasks: {len(self.tasks)}\")\n        print(f\"LLM: {self.llm_endpoint}\"\
    )\n        print(f\"{'='*80}\\n\")\n\n        for task in self.tasks:\n      \
    \      self.execute_task(task)\n            time.sleep(2)  # Rate limit\n\n  \
    \      self.results['end_time'] = time.time()\n        self.results['duration']\
    \ = self.results['end_time'] - self.results['start_time']\n\n        # Save results\n\
    \        with open('/workspace/results.json', 'w') as f:\n            json.dump(self.results,\
    \ f, indent=2)\n\n        print(f\"\\n{'='*80}\")\n        print(f\"WORKER COMPLETE:\
    \ {self.worker_id}\")\n        print(f\"Completed: {self.results['tasks_completed']}\"\
    )\n        print(f\"Failed: {self.results['tasks_failed']}\")\n        print(f\"\
    Duration: {self.results['duration']:.1f}s\")\n        print(f\"Total API Cost\
    \ Saved: ${self.results['tasks_completed'] * 0.015:.2f}\")\n        print(f\"\
    {'='*80}\")\n\nif __name__ == \"__main__\":\n    # Load tasks from ConfigMap\n\
    \    with open('/config/tasks.json', 'r') as f:\n        all_tasks = json.load(f)\n\
    \n    # Filter tasks for this worker (simplified - would use label selector)\n\
    \    worker_tasks = all_tasks[:5]  # Take first 5 as example\n\n    # Get worker\
    \ ID from environment\n    worker_id = os.getenv('WORKER_ID', 'unknown')\n\n \
    \   worker = HonestK8sWorker(worker_id, worker_tasks)\n    worker.run()\n"
kind: ConfigMap
metadata:
  name: worker-scripts
  namespace: honest-orchestration
