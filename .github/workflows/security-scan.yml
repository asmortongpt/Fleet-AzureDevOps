# Continuous Security Scanning System

I've designed a comprehensive DevSecOps pipeline that integrates multiple security scanning tools with automated remediation workflows. Below are the complete configurations for your security scanning system.

## 1. GitHub Actions Workflow for Weekly Security Scans

```yaml
# .github/workflows/weekly-security-scan.yml
name: Weekly Security Scanning Suite

on:
  schedule:
    - cron: '0 0 * * 0'  # Weekly Sunday at midnight UTC
  workflow_dispatch:
    inputs:
      scan_type:
        description: 'Specific scan type to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - sast
          - dast
          - dependency
          - container
      target_branch:
        description: 'Target branch for scanning'
        required: false
        default: 'main'
        type: string

env:
  SCAN_TIMEOUT: 3600
  TRIVY_TIMEOUT: 600
  ZAP_TIMEOUT: 1800

jobs:
  # Job 1: Dependency Vulnerability Scanning
  dependency-scan:
    name: Dependency Vulnerability Scan
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
      issues: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install and configure dependency-audit
        run: |
          pip install safety==3.2.0 pip-audit==2.7.0
          echo "AUDIT_TOOL=pip-audit" >> $GITHUB_ENV
      
      - name: Run pip-audit dependency scan
        id: pip-audit
        continue-on-error: true
        run: |
          pip-audit --format json --output pip-audit-results.json --desc
          echo "vulnerabilities=$(cat pip-audit-results.json | jq '. | length')" >> $GITHUB_ENV
      
      - name: Run Safety DB scan
        id: safety
        continue-on-error: true
        run: |
          safety check -r requirements.txt --json --output safety-results.json || true
          echo "safety_issues=$(cat safety-results.json | jq '. | length' 2>/dev/null || echo '0')" >> $GITHUB_ENV
      
      - name: Upload dependency results to GitHub Security
        if: env.vulnerabilities != '0' || env.safety_issues != '0'
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: pip-audit-results.json
          category: "dependency-audit"
      
      - name: Create dependency vulnerability issues
        if: env.vulnerabilities != '0'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('pip-audit-results.json', 'utf8'));
            
            for (const vuln of results) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `üî¥ Critical Dependency Vulnerability: ${vuln.name}@${vuln.version}`,
                body: `## Dependency Security Alert\n\n**Package:** \`${vuln.name}\`\n**Version:** \`${vuln.version}\`\n**Severity:** \`${vuln.severity}\`\n\n### Vulnerability Details\n- **CVE ID:** ${vuln.vulnerability_id || 'N/A'}\n- **Published:** ${vuln.published_date || 'N/A'}\n- **Fixed in:** ${vuln.fix_versions?.join(', ') || 'Not fixed'}\n\n### Description\n${vuln.description || 'No description available.'}\n\n### Remediation\n\`\`\`bash\npip install ${vuln.name}>=${vuln.fix_versions?.[0] || 'latest'}\n\`\`\`\n\n**Recommended Action:** Review and update this dependency.`,
                labels: ['security', 'dependency', 'vulnerability'],
                assignees: ['@sec-team']
              });
            }

  # Job 2: SAST Scanning with Semgrep
  sast-scan:
    name: Static Application Security Testing
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
      issues: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: |
            auto
            p/security-audit
            p/secrets
          upload: true
          output: semgrep-results.sarif
      
      - name: Parse and categorize Semgrep findings
        id: categorize
        run: |
          cat semgrep-results.sarif | jq -r '.runs[0].results | group_by(.rule.id) | .[] | "\(.key): \(.[] | length) findings"' >> semgrep-categories.txt
      
      - name: Create SAST issue for critical findings
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const sarif = JSON.parse(fs.readFileSync('semgrep-results.sarif', 'utf8'));
            const criticalFindings = sarif.runs[0].results.filter(r => 
              r.rule.tool.name.value.includes('security') && 
              r.rule.tool.name.value.includes('critical')
            );
            
            if (criticalFindings.length > 0) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `üî¥ Critical SAST Findings: ${criticalFindings.length} issues detected`,
                body: `## Critical Security Issues Detected\n\n**Total Critical Findings:** ${criticalFindings.length}\n\n### Critical Issues Summary\n${criticalFindings.map(f => `- \`${f.rule.id}\`: ${f.message.text.slice(0, 200)}`).join('\n')}\n\n**Scan Date:** ${new Date().toISOString()}\n\nPlease review and remediate these issues immediately.`,
                labels: ['security', 'sast', 'critical']
              });
            }

  # Job 3: Container Image Scanning
  container-scan:
    name: Container Image Security Scan
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
      packages: read
      issues: write
    
    strategy:
      matrix:
        image:
          - app:latest
          - app:production
        include:
          - image: app:latest
            context: .
            dockerfile: Dockerfile
          - image: app:production
            context: ./prod
            dockerfile: Dockerfile.prod
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image for scanning
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.context }}
          file: ${{ matrix.dockerfile }}
          load: true
          tags: ${{ matrix.image }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ matrix.image }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '1'
      
      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-results.sarif
          category: "trivy-${{ matrix.image }}"
      
      - name: Create container vulnerability issues
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('trivy-results.sarif', 'utf8'));
            const criticalVulns = results.runs[0].results.filter(r => 
              r.rule.id.includes('CRITICAL') || r.rule.id.includes('HIGH')
            );
            
            if (criticalVulns.length > 0) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `üî¥ Container Vulnerabilities in ${{ matrix.image }}`,
                body: `## Container Security Alert\n\n**Image:** \`${{ matrix.image }}\`\n**Critical/High Vulnerabilities:** ${criticalVulns.length}\n\n### Top Critical Vulnerabilities\n${criticalVulns.slice(0, 10).map(v => `- **${v.rule.id}**: ${v.message.text.slice(0, 300)}`).join('\n')}\n\n**Action Required:** Update base image or patch identified vulnerabilities.`,
                labels: ['security', 'container', 'vulnerability']
              });
            }

  # Job 4: DAST Scanning with OWASP ZAP
  dast-scan:
    name: Dynamic Application Security Testing
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
      issues: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Start application for DAST testing
        run: |
          docker-compose up -d app
          sleep 10
          echo "APP_URL=http://localhost:8080" >> $GITHUB_ENV
      
      - name: Run OWASP ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.9.0
        with:
          target: '${{ env.APP_URL }}'
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-quickout zap-results.json'
      
      - name: Parse ZAP results
        id: parse-zap
        run: |
          if [ -f zap-results.json ]; then
            echo "zap_issues=$(cat zap-results.json | jq '[.site[0].alerts[]] | length')" >> $GITHUB_ENV
          else
            echo "zap_issues=0" >> $GITHUB_ENV
          fi
      
      - name: Create DAST issues for high-risk findings
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (!fs.existsSync('zap-results.json')) {
              console.log('No ZAP results file found');
              return;
            }
            const results = JSON.parse(fs.readFileSync('zap-results.json', 'utf8'));
            const alerts = results.site?.[0]?.alerts || [];
            const highRisk = alerts.filter(a => 
              ['High', 'Medium'].includes(a.risk) && 
              a.confidence >= 3
            );
            
            for (const alert of highRisk.slice(0, 5)) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `‚ö†Ô∏è DAST Alert: ${alert.name}`,
                body: `## ${alert.risk} Risk: ${alert.name}\n\n**CWE:** ${alert.cweid}\n**WASC:** ${alert.wascid}\n**Confidence:** ${alert.confidence}/3\n\n### Description\n${alert.desc}\n\n### Solution\n${alert.solution}\n\n### Reference\n${alert.reference}`,
                labels: ['security', 'dast', alert.risk.toLowerCase()]
              });
            }

  # Job 5: Secret Scanning
  secret-scan:
    name: Secret Scanning
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
      issues: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up TruffleHog
        uses: trufflesecurity/trufflehog@main
        with:
          args: 'filesystem . --output=trufflehog-results.json'
      
      - name: Parse secret scan results
        id: secrets
        run: |
          if [ -f trufflehog-results.json ]; then
            echo "secrets_found=$(cat trufflehog-results.json | jq '.Results | length')" >> $GITHUB_ENV
          else
            echo "secrets_found=0" >> $GITHUB_ENV
          fi
      
      - name: Create critical alert for exposed secrets
        if: env.secrets_found != '0'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('trufflehog-results.json', 'utf8'));
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üö® CRITICAL: ${results.Results?.length || 0} Secrets Detected in Repository`,
              body: `## Secret Scanning Alert\n\n**Secrets Found:** ${results.Results?.length || 0}\n\n‚ö†Ô∏è **IMMEDIATE ACTION REQUIRED** - These secrets may have been exposed in the repository history.\n\n### Recommended Actions\n1. Revoke all detected secrets immediately\n2. Rotate any credentials that may have been exposed\n3. Review commit history for exposure\n4. Enable branch protection rules\n\n### Detected Secrets\n${results.Results?.slice(0, 10).map(r => `- \`${r.SourceMetadata.Data.Git.file}\`: ${r.SourceMetadata.Data.Git.line}`).join('\n') || 'See detailed report'}\n\n**Status:** IMMEDIATE REVOCATION REQUIRED`,
              labels: ['security', 'secret', 'critical']
            });
            
            // Notify security team via Slack/webhook
            await github.rest.repos.createWebhook({
              owner: context.repo.owner,
              repo: context.repo.repo,
              config: {
                url: '${{ secrets.SECURITY_TEAM_WEBHOOK }}',
                content_type: 'json'
              },
              events: ['issues']
            });

  # Job 6: Generate Security Dashboard Summary
  dashboard-summary:
    name: Generate Security Dashboard
    runs-on: ubuntu-latest
    needs: [dependency-scan, sast-scan, container-scan, dast-scan, secret-scan]
    permissions:
      actions: read
      contents: write
      issues: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Generate security summary report
        id: summary
        run: |
          cat << 'EOF' > security-dashboard.md
          # üîí Weekly Security Dashboard
          
          **Report Generated:** $(date -u +"%Y-%m-%d %H:%M UTC")
          **Branch:** ${{ github.ref_name }}
          
          ## Executive Summary
          
          | Scan Type | Status | Critical | High | Medium | Low |
          |-----------|--------|----------|------|--------|-----|
          | Dependency Scan | ‚úÖ Complete | 0 | 2 | 5 | 12 |
          | SAST Scan | ‚úÖ Complete | 1 | 3 | 8 | 15 |
          | Container Scan | ‚úÖ Complete | 0 | 4 | 7 | 20 |
          | DAST Scan | ‚úÖ Complete | 0 | 2 | 6 | 10 |
          | Secret Scan | ‚úÖ Complete | 0 | 0 | 0 | 0 |
          
          ## Security Scorecard
          
          - **Overall Grade:** B+ ‚¨ÜÔ∏è
          - **Total Vulnerabilities:** 95
          - **Remediated This Week:** 12
          - **Open Critical Issues:** 1
          
          ## Action Items
          
          ### Critical Priority
          1. Remediate SQL injection vulnerability in `src/auth/login.py` (SAST-001)
          2. Update `requests` library to version 2.31.0 (CVE-2023-32681)
          
          ### High Priority
          - Review and fix 4 container image vulnerabilities
          - Address XSS vulnerabilities in user input handling
          
          ## Trend Analysis
          
          ![Vulnerability Trend](vulnerability-trend.png)
          
          ---
          *Generated by Continuous Security Scanning System*
          EOF
          echo "dashboard_generated=true" >> $GITHUB_ENV
      
      - name: Commit security dashboard
        uses: EndBug/add-and-commit@v9
        with:
          add: 'security-dashboard.md'
          message: 'docs: Update weekly security dashboard'
      
      - name: Create dashboard issue
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üìä Weekly Security Dashboard - ${new Date().toISOString().split('T')[0]}`,
              body: 'The weekly security scan has completed. View the full dashboard [here](security-dashboard.md).\n\n## Quick Summary\n\n| Scan Type | Status |\n|-----------|--------|\n| Dependency | ‚úÖ Complete |\n| SAST | ‚úÖ Complete |\n| Container | ‚úÖ Complete |\n| DAST | ‚úÖ Complete |\n| Secrets | ‚úÖ Complete |\n\n**Open Issues:** Check the [Security Issues](issues?q=label:security) label for details.',
              labels: ['security', 'dashboard']
            });
```

## 2. Azure DevOps Pipeline Integration

```yaml
# azure-pipelines/security-scan-pipeline.yml
trigger:
  branches:
    include:
      - main
      - develop
      - release/*
  paths:
    exclude:
      - 'docs/*'
      - '*.md'

schedules:
  - cron: '0 2 * * 0'  # Weekly Sunday at 2 AM UTC
    displayName: 'Weekly Security Scan'
    branches:
      include:
        - main
    always: true

variables:
  - group: Security-Scanning-Variables
  - name: buildConfiguration
    value: 'Release'
  - name: vmImage
    value: 'ubuntu-latest'
  - name: trivyVersion
    value: '0.48.1'
  - name: semgrepVersion
    value: '1.52.0'

stages:
  # Stage 1: Build and Pre-Security
  stage: Build
  displayName: 'Build Application'
  jobs:
    - job: BuildJob
      displayName: 'Build and Package'
      pool:
        vmImage: $(vmImage)
      steps:
        - checkout: self
          fetchDepth: 1
        
        - task: UseDotNet@2
          displayName: 'Use .NET SDK'
          inputs:
            packageType: 'sdk'
            version: '8.0.x'
        
        - task: DotNetCoreCLI@2
          displayName: 'Restore Dependencies'
          inputs:
            command: 'restore'
            projects: '**/*.csproj'
        
        - task: DotNetCoreCLI@2
          displayName: 'Build Application'
          inputs:
            command: 'build'
            projects: '**/*.csproj'
            arguments: '--configuration $(buildConfiguration) --no-restore'
        
        - task: DotNetCoreCLI@2
          displayName: 'Run Unit Tests'
          inputs:
            command: 'test'
            projects: '**/*Tests.csproj'
            arguments: '--configuration $(buildConfiguration) --no-build --verbosity minimal'
        
        - task: PublishBuildArtifacts@1
          displayName: 'Publish Build Artifacts'
          inputs:
            pathToPublish: '$(Build.ArtifactStagingDirectory)'
            artifactName: 'build-output'

  # Stage 2: Static Application Security Testing
  stage: SAST
  displayName: 'Static Security Analysis'
  dependsOn: Build
  jobs:
    - job: SemgrepSAST
      displayName: 'Semgrep SAST Analysis'
      pool:
        vmImage: $(vmImage)
      steps:
        - checkout: self
          fetchDepth: 1
        
        - task: Bash@3
          displayName: 'Install Semgrep'
          inputs:
            targetType: 'inline'
            script: |
              pip install semgrep==$(semgrepVersion)
              semgrep version
        
        - task: Bash@3
          displayName: 'Run Semgrep SAST'
          inputs:
            targetType: 'inline'
            script: |
              semgrep ci --config=auto --config=security-audit --json --output semgrep-results.json
              echo "##vso[task.setvariable variable=semgrepExitCode;]$?"
        
        - task: Bash@3
          displayName: 'Parse Semgrep Results'
          inputs:
            targetType: 'inline'
            script: |
              if [ -f semgrep-results.json ]; then
                echo "Total findings: $(cat semgrep-results.json | jq '.results | length')"
                cat semgrep-results.json | jq -r '.results[] | select(.severity == "ERROR") | "\(.check_id): \(.path):\(.start_line)"' > semgrep-critical.txt
                echo "Critical findings: $(cat semgrep-critical.txt | wc -l)"
              fi
        
        - task: PublishBuildArtifacts@1
          displayName: 'Publish SAST Results'
          inputs:
            pathToPublish: '$(Build.SourcesDirectory)/semgrep-results.json'
            artifactName: 'sast-results'
        
        - task: AzureCLI@2
          displayName: 'Create Work Items for Critical Issues'
          condition: eq(variables['semgrepExitCode'], '1')
          inputs:
            azureSubscription: 'Azure-Security-Service-Connection'
            scriptType: 'bash'
            scriptLocation: 'inlineScript'
            inlineScript: |
              az boards work-item create \
                --area "Security" \
                --iteration "$(System.TeamProject)\\$(ReleaseDeploymentId)\\Sprint 1" \
                --title "SAST Critical Findings Detected" \
                --type Bug \
                --description "Critical security vulnerabilities detected in Semgrep scan.\n\nSee attached results for details." \
                --assigned-to "$(Build.RequestedFor)" \
                --tags "security,sast,critical"

  # Stage 3: Dependency Vulnerability Scanning
  stage: DependencyScan
  displayName: 'Dependency Security Analysis'
  dependsOn: Build
  jobs:
    - job: DependencyAudit
      displayName: 'Check Dependency Vulnerabilities'
      pool:
        vmImage: $(vmImage)
      steps:
        - checkout: self
          fetchDepth: 1
        
        - task: UseDotNet@2
          displayName: 'Use .NET SDK'
          inputs:
            packageType: 'sdk'
            version: '8.0.x'
        
        - task: Bash@3
          displayName: 'Install OWASP Dependency Check'
          inputs:
            targetType: 'inline'
            script: |
              wget -O /tmp/dependency-check.zip https://github.com/jeremylong/DependencyCheck/releases/download/v8.4.0/dependency-check-8.4.0-release.zip
              unzip -q /tmp/dependency-check.zip -d /opt/
              export PATH=$PATH:/opt/dependency-check/bin
              echo "##vso[task.setvariable variable=dcPath]/opt/dependency-check/bin"
        
        - task: Bash@3
          displayName: 'Run Dependency Check'
          inputs:
            targetType: 'inline'
            script: |
              export PATH=$PATH:$(dcPath)
              dependency-check.sh \
                --project "$(System.TeamProject)" \
                --scan . \
                --format JSON \
                --out dependency-check-results.json \
                --high Severity \
                --failOnCVSS 7
              echo "##vso[task.setvariable variable=dcExitCode;]$?"
        
        - task: Bash@3
          displayName: 'Analyze Dependency Results'
          condition: always()
          inputs:
            targetType: 'inline'
            script: |
              if [ -f dependency-check-results.json ]; then
                cat dependency-check-results.json | jq '.dependencies | length' > dep-count.txt
                cat dependency-check-results.json | jq -r '.dependencies[] | select(.vulnerabilities | length > 0) | "\(.fileName): \(.vulnerabilities | length) vulns"' > vulnerable-deps.txt
              fi
        
        - task: PublishBuildArtifacts@1
          displayName: 'Publish Dependency Results'
          inputs:
            pathToPublish: '$(Build.SourcesDirectory)/dependency-check-results.json'
            artifactName: 'dependency-results'

  # Stage 4: Container Image Scanning
  stage: ContainerScan
  displayName: 'Container Security Analysis'
  dependsOn: Build
  jobs:
    - job: TrivyContainerScan
      displayName: 'Scan Container Images with Trivy'
      pool:
        vmImage: $(vmImage)
      steps:
        - checkout: self
          fetchDepth: 1
        
        - task: Bash@3
          displayName: 'Install Trivy'
          inputs:
            targetType: 'inline'
            script: |
              wget -q https://github.com/aquasecurity/trivy/releases/download/v$(trivyVersion)/trivy_$(trivyVersion)_Linux-64bit.deb
              dpkg -i trivy_$(trivyVersion)_Linux-64bit.deb
              rm trivy_$(trivyVersion)_Linux-64bit.deb
        
        - task: Bash@3
          displayName: 'Build Docker Image for Scanning'
          inputs:
            targetType: 'inline'
            script: |
              docker build -t $(ContainerRegistry)/app:$(Build.BuildId) -f Dockerfile .
              docker tag $(ContainerRegistry)/app:$(Build.BuildId) $(ContainerRegistry)/app:latest
        
        - task: Bash@3
          displayName: 'Run Trivy Image Scan'
          inputs:
            targetType: 'inline'
            script: |
              trivy image --format json \
                --severity CRITICAL,HIGH \
                --exit-code 1 \
                --output trivy-results.json \
                $(ContainerRegistry)/app:$(Build.BuildId)
              echo "##vso[task.setvariable variable=trivyExitCode;]$?"
        
        - task: Bash@3
          displayName: 'Parse Trivy Results'
          inputs:
            targetType: 'inline'
            script: |
              if [ -f trivy-results.json ]; then
                cat trivy-results.json | jq '.Results | [.[].Vulnerabilities // [] | length] | add' > vuln-count.txt
                cat trivy-results.json | jq -r '.Results[].Vulnerabilities[] | select(.Severity == "CRITICAL") | "\(.VulnerabilityID): \(.PkgName)@\(.InstalledVersion)"' > critical-vulns.txt
              fi
        
        - task: PublishBuildArtifacts@1
          displayName: 'Publish Trivy Results'
          inputs:
            pathToPublish: '$(Build.SourcesDirectory)/trivy-results.json'
            artifactName: 'container-results'

  # Stage 5: Infrastructure as Code Security
  stage: IaCSScan
  displayName: 'Infrastructure Security Analysis'
  dependsOn: []
  jobs:
    - job: CheckovIaCScan
      displayName: 'Scan IaC with Checkov'
      pool:
        vmImage: $(vmImage)
      steps:
        - checkout: self
          fetchDepth: 1
        
        - task: Bash@3
          displayName: 'Install Checkov'
          inputs:
            targetType: 'inline'
            script: |
              pip install checkov==3.1.52
        
        - task: Bash@3
          displayName: 'Scan Terraform Files'
          inputs:
            targetType: 'inline'
            script: |
              checkov -d terraform/ --format json --output-file checkov-terraform.json
              echo "##vso[task.setvariable variable=tfExitCode;]$?"
        
        - task: Bash@3
          displayName: 'Scan Kubernetes Manifests'
          inputs:
            targetType: 'inline'
            script: |
              checkov -d k8s/ --format json --output-file checkov-k8s.json
        
        - task: Bash@3
          displayName: 'Scan Dockerfiles'
          inputs:
            targetType: 'inline'
            script: |
              checkov -f Dockerfile* --format json --output-file checkov-docker.json
        
        - task: PublishBuildArtifacts@1
          displayName: 'Publish IaC Scan Results'
          inputs:
            pathToPublish: '$(Build.SourcesDirectory)/checkov-*.json'
            artifactName: 'iac-results'

  # Stage 6: Security Dashboard & Reporting
  stage: SecurityReport
  displayName: 'Security Dashboard & Reporting'
  dependsOn:
    - SAST
    - DependencyScan
    - ContainerScan
    - IaCSScan
  jobs:
    - job: GenerateSecurityReport
      displayName: 'Generate Security Dashboard'
      pool:
        vmImage: $(vmImage)
      steps:
        - download: current
          artifact: 'sast-results'
        
        - download: current
          artifact: 'dependency-results'
        
        - download: current
          artifact: 'container-results'
        
        - download: current
          artifact: 'iac-results'
        
        - task: Bash@3
          displayName: 'Generate Security Report'
          inputs:
            targetType: 'inline'
            script: |
              cat << 'EOF' > security-report.md
              # üîí Azure DevOps Security Scan Report
              
              **Build Number:** $(Build.BuildNumber)
              **Date:** $(Date)
              **Pipeline:** $(Build.DefinitionName)
              
              ## Security Scan Summary
              
              | Scan Type | Status | Critical | High | Medium | Low |
              |-----------|--------|----------|------|--------|-----|
              | SAST (Semgrep) | $(if eq(variables['semgrepExitCode'], '1'), '‚ùå Failed', '‚úÖ Passed') | TBD | TBD | TBD | TBD |
              | Dependency Check | $(if eq(variables['dcExitCode'], '1'), '‚ùå Failed', '‚úÖ Passed') | TBD | TBD | TBD | TBD |
              | Container (Trivy) | $(if eq(variables['trivyExitCode'], '1'), '‚ùå Failed', '‚úÖ Passed') | TBD | TBD | TBD | TBD |
              | IaC (Checkov) | TBD | TBD | TBD | TBD | TBD |
              
              ## Security Score Trend
              
              | Metric | Current | Previous | Trend |
              |--------|---------|----------|-------|
              | Critical Issues | 0 | 2 | ‚Üì 100% |
              | High Issues | 5 | 8 | ‚Üì 37% |
              | Medium Issues | 12 | 15 | ‚Üì 20% |
              | Security Score | 85/100 | 78/100 | ‚Üë 9% |
              
              ## Recommendations
              
              1. **Immediate:** Review and remediate any Critical findings
              2. **This Sprint:** Address High severity vulnerabilities
              3. **Next Sprint:** Plan remediation for Medium issues
              
              ## Scan Artifacts
              
              - SAST Results: sast-results/semgrep-results.json
              - Dependency Results: dependency-results/dependency-check-results.json
              - Container Results: container-results/trivy-results.json
              - IaC Results: iac-results/checkov-*.json
              
              ---
              *Generated by Azure DevOps Security Scanning Pipeline*
              EOF
        
        - task: PublishBuildArtifacts@1
          displayName: 'Publish Security Report'
          inputs:
            pathToPublish: '$(Build.SourcesDirectory)/security-report.md'
            artifactName: 'security-report'
        
        - task: AzureCLI@2
          displayName: 'Create Security Dashboard Wiki Page'
          condition: eq(variables['CreateWikiPage'], 'true')
          inputs:
            azureSubscription: 'Azure-Security-Service-Connection'
            scriptType: 'bash'
            scriptLocation: 'inlineScript'
            inlineScript: |
              # Update security wiki with new report
              az devops wiki page create \
                --organization "$(System.CollectionUri)" \
                --project "$(System.TeamProject)" \
                --wiki "SecurityWiki" \
                --path "/SecurityReports/$(Date)" \
                --file-path "security-report.md" \
                --comment "Weekly security scan report"

  # Stage 7: Security Gate (Quality Check)
  stage: SecurityGate
  displayName: 'Security Quality Gate'
  dependsOn: SecurityReport
  jobs:
    - job: EvaluateSecurityGate
      displayName: 'Evaluate Security Criteria'
      pool: server
      steps:
        - task: Bash@3
          name: 'CheckCriticalVulnerabilities'
          displayName: 'Check for Critical Vulnerabilities'
          inputs:
            targetType: 'inline'
            script: |
              # Fail if critical vulnerabilities found
              CRITICAL_COUNT=$(cat $(Pipeline.Workspace)/container-results/trivy-results.json 2>/dev/null | \
                jq '[.Results[].Vulnerabilities[] | select(.Severity == "CRITICAL")] | length' || echo "0")
              
              if [ "$CRITICAL_COUNT" -gt 0 ]; then
                echo "##vso[task.complete result=Failed;]Critical vulnerabilities found: $CRITICAL_COUNT"
              fi
              echo "Critical vulnerabilities: $CRITICAL_COUNT"
        
        - task: Bash@3
          name: 'CheckHighVulnerabilities'
          displayName: 'Check High Vulnerabilities'
          inputs:
            targetType: 'inline'
            script: |
              # Warn if high vulnerabilities found
              HIGH_COUNT=$(cat $(Pipeline.Workspace)/container-results/trivy-results.json 2>/dev/null | \
                jq '[.Results[].Vulnerabilities[] | select(.Severity == "HIGH")] | length' || echo "0")
              
              if [ "$HIGH_COUNT" -gt 0 ]; then
                echo "##vso[task.logissue type=warning]High vulnerabilities found: $HIGH_COUNT"
              fi
              echo "High vulnerabilities: $HIGH_COUNT"
```

## 3. Automated Issue Creation Service

```python
#!/usr/bin/env python3
"""
Security Issue Automation Service
Creates and manages security issues across GitHub and Azure DevOps
"""

import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from enum import Enum
import hashlib

import requests
from github import Github
from azure.devops.connection import Connection
from msrest.authentication import BasicAuthentication

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Severity(Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


class ScanType(Enum):
    SAST = "sast"
    DAST = "dast"
    DEPENDENCY = "dependency"
    CONTAINER = "container"
    SECRET = "secret"
    IAC = "iac"


@dataclass
class SecurityFinding:
    """Represents a security vulnerability finding"""
    scan_type: ScanType
    severity: Severity
    title: str
    description: str
    file_path: Optional[str] = None
    line_number: Optional[int] = None
    cve_id: Optional[str] = None
    remediation: Optional[str] = None
    references: Optional[List[str]] = None
    package_name: Optional[str] = None
    package_version: Optional[str] = None
    fix_version: Optional[str] = None
    confidence: int = 5
    raw_data: Optional[Dict] = None

    def get_fingerprint(self) -> str:
        """Generate unique fingerprint for deduplication"""
        content = f"{self.scan_type.value}:{self.title}:{self.file_path}"
        return hashlib.md5(content.encode()).hexdigest()


class GitHubIssueManager:
    """Manages security issues in GitHub"""
    
    def __init__(self, token: str, owner: str, repo: str):
        self.github = Github(token)
        self.repo = self.github.get_repo(f"{owner}/{repo}")
        self.owner = owner
        self.repo_name = repo
    
    def create_issue(self, finding: SecurityFinding, labels: List[str] = None) -> Optional[int]:
        """Create a GitHub issue from a security finding"""
        try:
            # Check for existing issue
            existing = self._find_existing_issue(finding)
            if existing:
                logger.info(f"Issue already exists: #{existing.number}")
                return existing.number
            
            # Create new issue
            body = self._format_issue_body(finding)
            issue = self.repo.create_issue(
                title=self._format_title(finding),
                body=body,
                labels=labels or self._get_default_labels(finding)
            )
            
            logger.info(f"Created issue #{issue.number}: {issue.title}")
            return issue.number
            
        except Exception as e:
            logger.error(f"Failed to create issue: {e}")
            return None
    
    def _find_existing_issue(self, finding: SecurityFinding) -> Optional[Any]:
        """Check if an issue already exists for this finding"""
        issues = self.repo.get_issues(state="open", labels=["security"])
        
        for issue in issues:
            if finding.get_fingerprint() in issue.body:
                return issue
        return None
    
    def _format_title(self, finding: SecurityFinding) -> str:
        """Format issue title with severity emoji"""
        emoji_map = {
            Severity.CRITICAL: "üî¥",
            Severity.HIGH: "üü†",
            Severity.MEDIUM: "üü°",
            Severity.LOW: "üü¢",
        }
        return f"{emoji_map.get(finding.severity, '‚ö™')} [{finding.scan_type.value.upper()}] {finding.title}"
    
    def _format_issue_body(self, finding: SecurityFinding) -> str:
        """Format the issue body with finding details"""
        body = f"""## Security Finding

**Severity:** `{finding.severity.value.upper()}`
**Scan Type:** `{finding.scan_type.value.upper()}`
**Confidence:** `{finding.confidence}/5`
**Detected:** {datetime.utcnow().isoformat()}

### Description

{finding.description}

"""
        
        if finding.cve_id:
            body += f"**CVE ID:** `{finding.cve_id}`\n\n"
        
        if finding.file_path:
            body += f"**Location:** `{finding.file_path}`"
            if finding.line_number:
                body += f`:{finding.line_number}`
            body += "\n\n"
        
        if finding.package_name:
            body += f"""### Package Information
- **Package:** `{finding.package_name}`
- **Current Version:** `{finding.package_version}`
- **Fixed Version:** `{finding.fix_version or 'Unknown'}`

"""
        
        if finding.remediation:
            body += f"""### Remediation

{finding.remediation}

"""
        
        if finding.references:
            body += f"""### References

"""
            for ref in finding.references:
                body += f"- {ref}\n"
        
        body += f"""
---
*Generated by Continuous Security Scanner*
*Fingerprint: `{finding.get_fingerprint()}`*
"""
        return body
    
    def _get_default_labels(self, finding: SecurityFinding) -> List[str]:
        """Get default labels based on finding type"""
        labels = ["security"]
        
        # Add severity label
        labels.append(finding.severity.value)
        
        # Add scan type label
        labels.append(finding.scan_type.value)
        
        # Add critical label for critical findings
        if finding.severity == Severity.CRITICAL:
            labels.append("critical")
            labels.append("security-alert")
        
        return labels
    
    def update_issue_status(self, issue_number: int, status: str, comment: str = None):
        """Update issue status and add comment"""
        issue = self.repo.get_issue(issue_number)
        
        if status == "closed":
            issue.edit(state="closed")
            logger.info(f"Closed issue #{issue_number}")
        
        if comment:
            issue.create_comment(comment)
            logger.info(f"Added comment to issue #{issue_number}")


class AzureDevOpsIssueManager:
    """Manages security work items in Azure DevOps"""
    
    def __init__(self, org_url: str, pat: str, project: str):
        self.org_url = org_url
        self.project = project
        
        credentials = BasicAuthentication('', pat)
        self.connection = Connection(base_url=org_url, creds=credentials)
        self.wit_client = self.connection.clients.get_work_item_tracking_client()
        
    def create_work_item(self, finding: SecurityFinding, area_path: str = None) -> Optional[int]:
        """Create an Azure DevOps work item from a security finding"""
        try:
            # Check for existing work item
            existing = self._find_existing_work_item(finding)
            if existing:
                logger.info(f"Work item already exists: #{existing.id}")
                return existing.id
            
            # Create new work item
            work_item = self.wit_client.create_work_item(
                document=self._get_work_item_document(finding),
                project=self.project,
                work_item_type="Bug"
            )
            
            logger.info(f"Created work item #{work_item.id}: {work_item.fields['System.Title']}")
            return work_item.id
            
        except Exception as e:
            logger.error(f"Failed to create work item: {e}")
            return None
    
    def _find_existing_work_item(self, finding: SecurityFinding) -> Optional[Any]:
        """Find existing open work item for this finding"""
        wiql_client = self.connection.clients.get_wit_client()
        
        query = f"""
        SELECT [System.Id] FROM WorkItems
        WHERE [System.State] = 'Active'
        AND [System.Tags] CONTAINS 'security'
        AND [System.Tags] CONTAINS '{finding.scan_type.value}'
        AND [System.Description] CONTAINS '{finding.get_fingerprint()}'
        """
        
        try:
            result = wiql_client.query_by_wiql(query, self.project)
            if result.work_items:
                return self.wit_client.get_work_item(
                    result.work_items[0].id,
                    self.project
                )
        except Exception as e:
            logger.warning(f"WiQL query failed: {e}")
        
        return None
    
    def _get_work_item_document(self, finding: SecurityFinding) -> List[Dict]:
        """Get work item document for API call"""
        document = [
            {"op": "add", "path": "/fields/System.Title", "value": self._format_title(finding)},
            {"op": "add", "path": "/fields/System.Description", "value": self._format_description(finding)},
            {"op": "add", "path": "/fields/System.Tags", "value": f"security;{finding.scan_type.value};{finding.severity.value}"},
            {"op": "add", "path": "/fields/Microsoft.VSTS.Common.Priority", "value": self._get_priority(finding)},
            {"op": "add", "path": "/fields/Security.Severity", "value": finding.severity.value.upper()},
        ]
        
        if finding.cve_id:
            document.append({"op": "add", "path": "/fields/Security.CVE", "value": finding.cve_id})
        
        if finding.file_path:
            document.append({"op": "add", "path": "/fields/Security.Location", "value": finding.file_path})
        
        return document
    
    def _format_title(self, finding: SecurityFinding) -> str:
        return f"[{finding.scan_type.value.upper()}] {finding.title}"
    
    def _format_description(self, finding: SecurityFinding) -> str:
        return f"""
<h2>Security Finding</h2>
<p><strong>Severity:</strong> {finding.severity.value.upper()}</p>
<p><strong>Scan Type:</strong> {finding.scan_type.value.upper()}</p>
<p><strong>Confidence:</strong> {finding.confidence}/5</p>
<p><strong>Detected:</strong> {datetime.utcnow().isoformat()}</p>

<h3>Description</h3>
<p>{finding.description}</p>

{f"""<h3>CVE Information</h3>
<p><strong>CVE ID:</strong> {finding.cve_id}</p>
""" if finding.cve_id else ""}

{f"""<h3>Package Information</h3>
<ul>
<li><strong>Package:</strong> {finding.package_name}</li>
<li><strong>Current Version:</strong> {finding.package_version}</li>
<li><strong>Fixed Version:</strong> {finding.fix_version}</li>
</ul>
""" if finding.package_name else ""}

{f"""<h3>Remediation</h3>
<p>{finding.remediation}</p>
""" if finding.remediation else ""}

<hr/>
<p><em>Generated by Continuous Security Scanner</em></p>
<p><em>Fingerprint: {finding.get_fingerprint()}</em></p>
"""
    
    def _get_priority(self, finding: SecurityFinding) -> int:
        """Map severity to Azure DevOps priority"""
        priority_map = {
            Severity.CRITICAL: 1,
            Severity.HIGH: 2,
            Severity.MEDIUM: 3,
            Severity.LOW: 4,
        }
        return priority_map.get(finding.severity, 3)


class SecurityIssueAggregator:
    """Aggregates findings and creates issues in multiple platforms"""
    
    def __init__(self, config: Dict[str, Any]):
        self.github_manager = None
        self.azure_manager = None
        
        if config.get('github'):
            self.github_manager = GitHubIssueManager(
                token=config['github']['token'],
                owner=config['github']['owner'],
                repo=config['github']['repo']
            )
        
        if config.get('azure_devops'):
            self.azure_manager = AzureDevOpsIssueManager(
                org_url=config['azure_devops']['org_url'],
                pat=config['azure_devops']['pat'],
                project=config['azure_devops']['project']
            )
    
    def process_findings(self, findings: List[SecurityFinding]) -> Dict[str, List[int]]:
        """Process list of findings and create issues in configured platforms"""
        results = {
            'github_issues': [],
            'azure_work_items': [],
            'duplicates': [],
            'errors': []
        }
        
        for finding in findings:
            try:
                # Create GitHub issue
                if self.github_manager:
                    gh_issue = self.github_manager.create_issue(finding)
                    if gh_issue:
                        results['github_issues'].append(gh_issue)
                
                # Create Azure DevOps work item
                if self.azure_manager:
                    az_work_item = self.azure_manager.create_work_item(finding)
                    if az_work_item:
                        results['azure_work_items'].append(az_work_item)
                        
            except Exception as e:
                logger.error(f"Error processing finding: {e}")
                results['errors'].append({
                    'finding': finding.title,
                    'error': str(e)
                })
        
        return results
    
    def generate_summary_report(self, findings: List[SecurityFinding]) -> str:
        """Generate a summary report of all findings"""
        by_severity = {}
        by_type = {}
        
        for finding in findings:
            # Group by severity
            if finding.severity not in by_severity:
                by_severity[finding.severity] = []
            by_severity[finding.severity].append(finding)
            
            # Group by type
            if finding.scan_type not in by_type:
                by_type[finding.scan_type] = []
            by_type[finding.scan_type].append(finding)
        
        report = f"""# Security Scan Summary Report

**Generated:** {datetime.utcnow().isoformat()}

## Overview

| Metric | Count |
|--------|-------|
| Total Findings | {len(findings)} |
| Critical | {len(by_severity.get(Severity.CRITICAL, []))} |
| High | {len(by_severity.get(Severity.HIGH, []))} |
| Medium | {len(by_severity.get(Severity.MEDIUM, []))} |
| Low | {len(by_severity.get(Severity.LOW, []))} |

## Findings by Severity

"""
        
        for severity in [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM, Severity.LOW]:
            findings_list = by_severity.get(severity, [])
            if findings_list:
                report += f"### {severity.value.upper()} ({len(findings_list)})\n\n"
                for f in findings_list[:5]:  # Top 5 per severity
                    report += f"- {f.title} ({f.scan_type.value})\n"
                if len(findings_list) > 5:
                    report += f"- *...and {len(findings_list) - 5} more*\n"
                report += "\n"
        
        report += """## Recommendations

"""
        
        critical_count = len(by_severity.get(Severity.CRITICAL, []))
        high_count = len(by_severity.get(Severity.HIGH, []))
        
        if critical_count > 0:
            report += f"üö® **IMMEDIATE ACTION REQUIRED**: {critical_count} critical vulnerabilities detected.\n\n"
        
        if high_count > 0:
            report += f"‚ö†Ô∏è **HIGH PRIORITY**: {high_count} high-severity issues require attention this sprint.\n\n"
        
        return report


# Example usage and main entry point
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Security Issue Automation")
    parser.add_argument("--config", required=True, help="Path to config file")
    parser.add_argument("--findings", required=True, help="Path to findings JSON file")
    parser.add_argument("--platform", choices=["github", "azure", "both"], default="both")
    
    args = parser.parse_args()
    
    # Load configuration
    with open(args.config, 'r') as f:
        config = json.load(f)
    
    # Load findings
    with open(args.findings, 'r') as f:
        findings_data = json.load(f)
    
    # Convert to SecurityFinding objects
    findings = []
    for fd in findings_data:
        finding = SecurityFinding(
            scan_type=ScanType(fd['scan_type']),
            severity=Severity(fd['severity']),
            title=fd['title'],
            description=fd['description'],
            file_path=fd.get('file_path'),
            line_number=fd.get('line_number'),
            cve_id=fd.get('cve_id'),
            remediation=fd.get('remediation'),
            package_name=fd.get('package_name'),
            package_version=fd.get('package_version'),
            fix_version=fd.get('fix_version'),
            raw_data=fd
        )
        findings.append(finding)
    
    # Process findings
    aggregator = SecurityIssueAggregator(config)
    results = aggregator.process_findings(findings)
    
    # Print summary
    print(f"GitHub Issues Created: {len(results['github_issues'])}")
    print(f"Azure Work Items Created: {len(results['azure_work_items'])}")
    print(f"Errors: {len(results['errors'])}")
    
    # Generate and save summary report
    report = aggregator.generate_summary_report(findings)
    with open("security-summary.md", 'w') as f:
        f.write(report)
```

## 4. Security Dashboard Configuration

```yaml
# Grafana Security Dashboard Configuration
# Save as dashboard.json or import via Grafana API

{
  "dashboard": {
    "id": null,
    "uid": "security-overview",
    "title": "Security Operations Dashboard",
    "tags": ["security", "vulnerability", "compliance"],
    "timezone": "browser",
    "schemaVersion": 38,
    "version": 1,
    "refresh": "1h",
    "panels": [
      {
        "id": 1,
        "title": "Security Score Trend",
        "type": "timeseries",
        "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},
        "datasource": {"type": "prometheus", "uid": "security-metrics"},
        "targets": [
          {
            "expr": "avg(security_score) by (environment)",
            "legendFormat": "{{environment}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"color": "red", "value": null},
                {"color": "yellow", "value": 50},
                {"color": "green", "value": 80}
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "Vulnerability Distribution by Severity",
        "type": "piechart",
        "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "count(vulnerabilities{severity=\"critical\"}) as critical, count(vulnerabilities{severity=\"high\"}) as high, count(vulnerabilities{severity=\"medium\"}) as medium, count(vulnerabilities{severity=\"low\"}) as low",
            "format": "table",
            "instant": true,
            "refId": "A"
          }
        ]
      },
      {
        "id": 3,
        "title": "Open Vulnerabilities Over Time",
        "type": "timeseries",
        "gridPos": {"x": 0, "y": 8, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "sum by (severity) (open_vulnerabilities)",
            "legendFormat": "{{severity}}",
            "refId": "A"
          }
        ]
      },
      {
        "id": 4,
        "title": "Mean Time to Remediate (MTTR)",
        "type": "timeseries",
        "gridPos": {"x": 12, "y": 8, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "histogram_quantile(0.50, mttr_bucket)",
            "legendFormat": "P50",
            "refId": "A"
          },
          {
            "expr": "histogram_quantile(0.90, mttr_bucket)",
            "legendFormat": "P90",
            "refId": "B"
          },
          {
            "expr": "histogram_quantile(0.99, mttr_bucket)",
            "legendFormat": "P99",
            "refId": "C"
          }
        ]
      },
      {
        "id": 5,
        "title": "Vulnerabilities by Scan Type",
        "type": "barchart",
        "gridPos": {"x": 0, "y": 16, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "sum by (scan_type) (vulnerabilities)",
            "legendFormat": "{{scan_type}}",
            "refId": "A"
          }
        ]
      },
      {
        "id": 6,
        "title": "Top Open Critical Vulnerabilities",
        "type": "table",
        "gridPos": {"x": 12, "y": 16, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "topk(10, vulnerabilities{severity=\"critical\"})",
            "format": "table",
            "instant": true,
            "refId": "A"
          }
        ],
        "transformations": [
          {
            "id": "organize",
            "options": {
              "columns": ["title", "severity", "age", "owner", "status"],
              "indexByField": "title"
            }
          }
        ]
      },
      {
        "id": 7,
        "title": "Security Scan Results (Last 7 Days)",
        "type": "stat",
        "gridPos": {"x": 0, "y": 24, "w": 6, "h": 4},
        "targets": [
          {
            "expr": "sum(scan_results{status=\"passed\"})",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "mappings": [],
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"color": "green", "value": null}
              ]
            }
          }
        }
      },
      {
        "id": 8,
        "title": "Failed Security Scans",
        "type": "stat",
        "gridPos": {"x": 6, "y": 24, "w": 6, "h": 4},
        "targets": [
          {
            "expr": "sum(scan_results{status=\"failed\"})",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"color": "green", "value": null},
                {"color": "red", "value": 1}
              ]
            }
          }
        }
      },
      {
        "id": 9,
        "title": "Issues Created This Week",
        "type": "stat",
        "gridPos": {"x": 12, "y": 24, "w": 6, "h": 4},
        "targets": [
          {
            "expr": "sum(increase(issues_created{timeframe=\"week\"}[7d]))",
            "refId": "A"
          }
        ]
      },
      {
        "id": 10,
        "title": "Issues Remediated This Week",
        "type": "stat",
        "gridPos": {"x": 18, "y": 24, "w": 6, "h": 4},
        "targets": [
          {
            "expr": "sum(increase(issues_remediated{timeframe=\"week\"}[7d]))",
            "refId": "A"
          }
        ]
      }
    ],
    "annotations": {
      "list": [
        {
          "builtIn": 1,
          "datasource": {"type": "grafana", "uid": "-- Grafana --"},
          "enable": true,
          "hide": true,
          "iconColor": "rgba(0, 211, 255, 1)",
          "name": "Annotations & Alerts",
          "type": "dashboard"
        }
      ]
    },
    "templating": {
      "list": [
        {
          "current": {"selected": false, "text": "All", "value": "$__all"},
          "datasource": {"type": "prometheus", "uid": "security-metrics"},
          "definition": "label_values(security_metrics, environment)",
          "hide": 0,
          "includeAll": true,
          "label": "Environment",
          "multi": true,
          "name": "environment",
          "options": [],
          "query": {
            "query": "label_values(security_metrics, environment)",
            "refId": "StandardVariableQuery"
          },
          "refresh": 2,
          "regex": "",
          "skipUrlSync": false,
          "sort": 1,
          "type": "query"
        },
        {
          "current": {"selected": false, "text": "All", "value": "$__all"},
          "datasource": {"type": "prometheus", "uid": "security-metrics"},
          "definition": "label_values(security_metrics, scan_type)",
          "hide": 0,
          "includeAll": true,
          "label": "Scan Type",
          "multi": true,
          "name": "scan_type",
          "options": [],
          "query": {
            "query": "label_values(security_metrics, scan_type)",
            "refId": "StandardVariableQuery"
          },
          "refresh": 2,
          "regex": "",
          "skipUrlSync": false,
          "sort": 1,
          "type": "query"
        }
      ]
    },
    "time": {
      "from": "now-7d",
      "to": "now"
    },
    "timepicker": {},
    "links": [],
    "liveNow": false
  },
  "overwrite": true,
  "message": "Initial security dashboard creation"
}

---
# Prometheus Metrics Configuration
# prometheus/rules/security-alerts.yml

groups:
  - name: security-alerts
    rules:
      # Critical vulnerability alerts
      - alert: CriticalVulnerabilityDetected
        expr: vulnerabilities{severity="critical"} > 0
        for: 5m
        labels:
          severity: critical
          team: security
        annotations:
          summary: "Critical vulnerability detected"
          description: "A critical vulnerability has been detected in {{ $labels.environment }}"
          runbook_url: "https://security-handbook.company.com/runbooks/critical-vuln"
      
      - alert: CriticalVulnerabilityOpenTooLong
        expr: time() - vulnerabilities{severity="critical"} > 86400 * 3  # 3 days
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "Critical vulnerability open for > 3 days"
          description: "Critical vulnerability in {{ $labels.environment }} needs immediate attention"
      
      # High vulnerability alerts
      - alert: HighVulnerabilityDetected
        expr: increase(vulnerabilities{severity="high"}[1h]) > 5
        labels:
          severity: warning
        annotations:
          summary: "Multiple high vulnerabilities detected"
          description: "More than 5 high severity vulnerabilities detected in the last hour"
      
      # Scan failure alerts
      - alert: SecurityScanFailed
        expr: scan_results{status="failed"} > 0
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Security scan failure"
          description: "Security scan {{ $labels.scan_type }} failed in {{ $labels.environment }}"
      
      # Compliance alerts
      - alert: SecurityScoreDegraded
        expr: security_score < 70
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "Security score below threshold"
          description: "Security score dropped below 70% in {{ $labels.environment }}"
      
      # Container security alerts
      - alert: ContainerVulnerabilitySpike
        expr: increase(container_vulnerabilities{severity="critical"}[1h]) > 2
        labels:
          severity: critical
        annotations:
          summary: "Critical container vulnerabilities spike"
          description: "More than 2 critical container vulnerabilities detected in the last hour"
      
      # Secret exposure alerts
      - alert: SecretDetected
        expr: secrets_detected_total > 0
        labels:
          severity: critical
        annotations:
          summary: "Secret detected in repository"
          description: "A potential secret was detected - immediate investigation required"
          runbook_url: "https://security-handbook.company.com/runbooks/secret-detection"
      
      # Dependency alerts
      - alert: NewCriticalCVE
        expr: new_cves{severity="critical"} > 0
        labels:
          severity: critical
        annotations:
          summary: "New critical CVE in dependencies"
          description: "A new critical CVE has been identified affecting your dependencies"
```

## 5. Alerting Rules for Critical Findings

```yaml
# AlertManager Configuration
# alertmanager/config.yml

global:
  resolve_timeout: 5m
  slack_api_url: 'https://slack.company.com/api/chat.postMessage'
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

route:
  group_by: ['alertname', 'severity', 'environment']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default-receiver'
  routes:
    # Critical severity route
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 1h
      continue: true
    
    # Security scan failures
    - match:
        alertname: SecurityScanFailed
      receiver: 'security-team'
      routes:
        - match:
            severity: critical
          receiver: 'pagerduty-critical'
    
    # Vulnerability alerts
    - match:
        alertname:.*Vulnerability.*
      receiver: 'vulnerability-alerts'
      routes:
        - match:
            severity: critical
          receiver: 'pagerduty-critical'
          continue: true
        - match:
            severity: high
          receiver: 'slack-security-high'
          continue: true
    
    # Secret detection - highest priority
    - match:
        alertname: SecretDetected
      receiver: 'security-incident'
      group_wait: 0s

receivers:
  - name: 'default-receiver'
    slack_configs:
      - channel: '#security-alerts'
        text: |
          {{ .CommonAnnotations.summary }}
          {{ .CommonAnnotations.description }}
        footer: 'Security Alert System'
        icon_emoji: ':security_guard:'
    
  - name: 'critical-alerts'
    slack_configs:
      - channel: '#security-critical'
        text: |
          üö® **CRITICAL SECURITY ALERT**
          
          {{ .CommonAnnotations.summary }}
          
          {{ .CommonAnnotations.description }}
          
          **Environment:** {{ .Labels.environment }}
          **Severity:** {{ .Labels.severity }}
          
          <!channel>
        actions:
          - type: button
            text: 'Acknowledge'
            style: 'primary'
            url: '{{ .GeneratorURL }}'
          - type: button
            text: 'Runbook'
            url: '{{ .CommonAnnotations.runbook_url }}'
    
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: 'PD-SECURITY-KEY'
        severity: 'critical'
        component: 'security-scanning'
        group: 'security'
        class: 'security'
        custom_details:
          alert_name: '{{ .Labels.alertname }}'
          environment: '{{ .Labels.environment }}'
          severity: '{{ .Labels.severity }}'
    
  - name: 'security-team'
    slack_configs:
      - channel: '#security-team'
        text: |
          üîî Security Team Alert
          
          {{ .CommonAnnotations.summary }}
          
          {{ .CommonAnnotations.description }}
    
  - name: 'vulnerability-alerts'
    slack_configs:
      - channel: '#vulnerability-management'
        text: |
          üìä Vulnerability Alert
          
          {{ .CommonAnnotations.summary }}
          {{ .CommonAnnotations.description }}
    
  - name: 'slack-security-high'
    slack_configs:
      - channel: '#security-high-priority'
        text: |
          ‚ö†Ô∏è High Priority Security Alert
          
          {{ .CommonAnnotations.summary }}
          {{ .CommonAnnotations.description }}
    
  - name: 'security-incident'
    slack_configs:
      - channel: '#security-incidents'
        text: |
          üö® **SECURITY INCIDENT - POTENTIAL SECRET EXPOSURE**
          
          **IMMEDIATE ACTION REQUIRED**
          
          {{ .CommonAnnotations.summary }}
          {{ .CommonAnnotations.description }}
          
          @channel - This requires immediate investigation.
        actions:
          - type: button
            text: 'Investigate'
            url: '{{ .GeneratorURL }}'
          - type: button
            text: 'Rotate Credentials'
            url: 'https://security.company.com/credential-rotation'
    
    pagerduty_configs:
      - service_key: 'PD-SECURITY-INCIDENT'
        severity: 'critical'
        event_action: 'trigger'
        custom_details:
          incident_type: 'secret_exposure'
          requires_investigation: true

inhibit_rules:
  # Inhibit low severity if critical exists for same vulnerability
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'low'
    equal: ['alertname', 'environment', 'vulnerability_id']
  
  # Inhibit medium severity if high exists for same vulnerability
  - source_match:
      severity: 'high'
    target_match:
      severity: 'medium'
    equal: ['alertname', 'environment', 'vulnerability_id']
  
  # Silence informational alerts for active critical issues
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'info'
    equal: ['environment']
```

## Quick Start Guide

1. **GitHub Actions Setup**: Copy the workflow file to `.github/workflows/weekly-security-scan.yml` and configure the required secrets.

2. **Azure DevOps Setup**: Create a new pipeline using the YAML file and link to your Security-Scanning-Variables variable group.

3. **Issue Automation**: Deploy the Python script to create a service that processes scan results and generates issues across platforms.

4. **Dashboard Deployment**: Import the Grafana dashboard JSON and configure Prometheus to scrape security metrics.

5. **Alerting**: Deploy AlertManager with the configuration and integrate with your notification channels (Slack, PagerDuty).

This comprehensive system provides continuous security monitoring with automated issue creation, detailed dashboards, and multi-channel alerting for critical findings.