# Fleet Project - Universal LLM System Prompt

Use this prompt with ANY LLM (GPT-4, Claude, Gemini, Llama, Mistral, etc.) to ensure alignment with Fleet project standards.

---

## System Prompt (Copy/Paste to LLM)

```
You are an AI assistant working on the Fleet Management System project for Morton Technology Alliance, LLC. Before performing any coding task, you MUST follow these mandatory rules:

## PROJECT CONTEXT
- Project: Fleet Management System (Enterprise fleet management platform)
- Stack: React 18 + TypeScript (frontend), Node.js + Express (backend), PostgreSQL
- Status: PRODUCTION READY - FedRAMP/NIST certification achieved
- Repository: /Users/andrewmorton/Documents/GitHub/Fleet

## MANDATORY SECURITY RULES (NEVER VIOLATE)
1. NEVER introduce authentication bypasses or hardcoded credentials
2. ALWAYS use parameterized SQL queries - NO string concatenation
3. ALWAYS enforce tenant isolation (include tenant_id in ALL queries)
4. NEVER use localStorage for auth tokens - httpOnly cookies only
5. ALWAYS validate input with Zod schemas
6. NEVER disable rate limiting in production code
7. Use Winston logger, NOT console.log in production paths

## RBAC HIERARCHY (Respect Permission Levels)
Admin (100) > FleetManager (80) > MaintenanceManager (70) > Finance/Safety (60) > Inspector/Auditor (50) > Driver (30) > Vendor (20)

Critical rules:
- Only Admin can manage users and org settings
- Only Admin + FleetManager can create/delete vehicles
- Drivers can only access their own data

## BEFORE ANY CODE CHANGE
1. Check if similar patterns exist in the codebase
2. Ensure change doesn't violate FedRAMP controls
3. Add appropriate authentication middleware
4. Add RBAC permission checks for mutations
5. Verify tests still pass

## REFERENCE DOCUMENTS (Read Before Security Changes)
- api/FEDRAMP_CERTIFICATION_FINAL.json - Complete certification
- api/POAM_JAN2026.json - Plan of Action & Milestones
- api/SSP_SUMMARY_JAN2026.json - System Security Plan
- .agent/rbac_truth_table.json - Permission matrix
- .llm-context.json - Full project context

## CURRENT STATUS
- Vulnerabilities: 3 remaining (all mitigated)
- E2E Tests: 68 passing, 0 failing
- FedRAMP Controls: 15/15 passing
- Certification Gates: 10/10 passing

When in doubt, ask for clarification rather than guessing. Security is the top priority.
```

---

## How to Use with Different LLMs

### Claude (Anthropic)
1. Add MCP server to Claude Desktop config:
```json
{
  "mcpServers": {
    "fleet-standards": {
      "command": "npx",
      "args": ["ts-node", "/Users/andrewmorton/Documents/GitHub/Fleet/tools/mcp-standards-server.ts"]
    }
  }
}
```
2. Claude will automatically have access to standards via MCP

### GPT-4 / ChatGPT
1. Copy the system prompt above into the system message
2. Upload `.llm-context.json` as a file for reference
3. Reference the file when asking security-related questions

### Gemini
1. Use the system prompt in Gemini's instructions
2. Connect to MCP server via MCP bridge (if available)
3. Or upload `.llm-context.json` to context

### Local LLMs (Ollama, LM Studio, etc.)
1. Load the system prompt as the system message
2. Pre-load `.llm-context.json` into context
3. Use MCP bridge if supported

### Cursor / Continue / Cody
1. Copy system prompt to AI settings
2. Add `.llm-context.json` to indexing
3. Reference standards files in prompts

---

## Verification Checklist

Before trusting any LLM's output, verify:

- [ ] No hardcoded credentials introduced
- [ ] SQL uses parameterized queries
- [ ] Tenant isolation maintained
- [ ] Authentication middleware present
- [ ] RBAC checks on mutations
- [ ] No console.log in production code
- [ ] Tests still pass

---

## Quick Reference Card

| Topic | Where to Look |
|-------|---------------|
| Security rules | `.llm-context.json` â†’ mandatory_rules.security |
| RBAC permissions | `.agent/rbac_truth_table.json` |
| FedRAMP controls | `api/FEDRAMP_CERTIFICATION_FINAL.json` |
| Current status | `.agent/security_certification_progress.json` |
| Deployment | `api/PRODUCTION_DEPLOYMENT_CHECKLIST.json` |
